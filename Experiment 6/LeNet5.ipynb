{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slug9yi1TdR6"
      },
      "source": [
        "<a href=\"https://kritikseth.github.io/ipynbtagredirect\" target=\"_parent\"><img src=\"https://raw.githack.com/kritikseth/kritikseth/master/assets/icons/kritik_ipynbtagredirect.svg\" alt=\"Kritik Seth\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVl5mz1DTUSl",
        "outputId": "6f48f6b4-48b6-45cd-8d21-c7065a6c1fc7"
      },
      "source": [
        "!pip install swachhdata -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 133kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 327kB 13.4MB/s \n",
            "\u001b[?25h  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTFWG9RTgszw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from swachhdata.image import ImageNet, image_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocq_5_mSQL4J"
      },
      "source": [
        "class LeNet5:\n",
        "    def __init__(self):\n",
        "        self._num_classes = None\n",
        "        self._epochs = None\n",
        "        self._optimizer = None\n",
        "        self._loss = None\n",
        "        self._metrics = []\n",
        "        self._X, self._y = None, None\n",
        "        self.__fit, self.__train = False, False\n",
        "        self._model = None\n",
        "    \n",
        "    def _get_architecture(self):\n",
        "        return tf.keras.models.Sequential([\n",
        "                    tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
        "                    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "                    \n",
        "                    tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='tanh', strides=(1, 1), padding='same', input_shape=(32, 32, 1)),\n",
        "                    tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "                    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='tanh', strides=(1, 1), padding='valid'),\n",
        "                    tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "                    tf.keras.layers.Flatten(),\n",
        "                    tf.keras.layers.Dense(120, activation='tanh'),\n",
        "                    tf.keras.layers.Dense(84, activation='tanh'),\n",
        "                    tf.keras.layers.Dense(units=self._num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    def _compile(self):\n",
        "        self._model.compile(optimizer=self._optimizer,\n",
        "                                           loss=self._loss,\n",
        "                                           metrics=self._metrics)\n",
        "    \n",
        "    def fit(self, X, y, optimizer, loss, metrics=['acc'], summary=False):\n",
        "        self._X, self._y = X, y\n",
        "        self._optimizer, self._loss, self._metrics = optimizer, loss, metrics\n",
        "        self._num_classes = len(np.unique(self._y))\n",
        "        self._model = self._get_architecture()\n",
        "        self._compile()\n",
        "        if summary:\n",
        "            print(self._model.summary())\n",
        "        self.__fit = True\n",
        "    \n",
        "    def train(self, **kwargs):\n",
        "        try:\n",
        "            assert(self.__fit)\n",
        "        except:\n",
        "            print(f'method fit needs to be called before train')\n",
        "\n",
        "        self._model.fit(**kwargs)\n",
        "        self.__train = True\n",
        "    \n",
        "    def predict(self, X):\n",
        "        try:\n",
        "            assert(self.__train)\n",
        "        except:\n",
        "            print(f'model needs to be trained called before predicting')\n",
        "        return self._model.predict(X)\n",
        "    \n",
        "    def evaluate(self, X, y):\n",
        "        try:\n",
        "            assert(self.__train)\n",
        "        except:\n",
        "            print(f'model needs to be trained called before evaluating')\n",
        "        return self._model.evaluate(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCegL86hR3GS"
      },
      "source": [
        "ch = tf.keras.callbacks.ModelCheckpoint(filepath='model.h5',\n",
        "                                        monitor='val_loss',\n",
        "                                        mode='auto',\n",
        "                                        save_best_only=True)\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                      min_delta=0.05,\n",
        "                                      patience=1,\n",
        "                                      mode='min',\n",
        "                                      restore_best_weights=True)\n",
        "\n",
        "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                          factor=0.01,\n",
        "                                          patience=1,\n",
        "                                          mode='min')\n",
        "\n",
        "class MonitorAccLoss(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('val_loss') < 0.5) and (logs.get('val_acc') > 0.75):\n",
        "            print('\\nOptimum Loss & Accuracy achieved, cancelling training!')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "mal = MonitorAccLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR1mSj1ubr1V"
      },
      "source": [
        "##ImageNet Cats vs Dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goW9QkndceQS"
      },
      "source": [
        "indt = {'Cat': 'n02124075', 'Dog': 'n02106662'}\n",
        "\n",
        "img_rows, img_cols = 224, 224\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "num_test = num_valid = 120\n",
        "test_per_cat = num_test//len(indt)\n",
        "valid_per_cat = num_valid//len(indt)\n",
        "\n",
        "input_dim = (num_test, img_rows, img_cols, 3)\n",
        "\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W10xobqbvW4"
      },
      "source": [
        "imgnet = ImageNet(img_shape=input_shape, total_img=num_test*3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k7pMZTUdE_S"
      },
      "source": [
        "images, labels = imgnet.fetch(indt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuJMNspEdb0H"
      },
      "source": [
        "X_train, X_test, y_train, y_test = image_split(images, labels, split_size=0.8, random_state=42)\n",
        "X_test, X_val, y_test, y_val = image_split(X_test, y_test, split_size=0.5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCOrOZLvQJcw"
      },
      "source": [
        "lenet5 = LeNet5()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAHZQstlQ13U"
      },
      "source": [
        "lenet5.fit(X_train, y_train, optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWDmLMGRHKR"
      },
      "source": [
        "lenet5.train(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=64, epochs=20, callbacks=[ch, es, lr, mal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaBeQIxDR9W0"
      },
      "source": [
        "lenet5.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNrTAnrbfFR"
      },
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkquuWClc_Vj"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YisNss5uSvXk"
      },
      "source": [
        "lenet5 = LeNet5()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T_x7gfcSvXk"
      },
      "source": [
        "lenet5.fit(X_train, y_train, optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQL-O6JFSvXl"
      },
      "source": [
        "lenet5.train(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=64, epochs=20, callbacks=[ch, es, lr, mal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf3O_b0DSvXl"
      },
      "source": [
        "lenet5.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI5oFhiabiQt"
      },
      "source": [
        "## CIFAR100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QdhlpwbkS_"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGucHHD_Sv4j"
      },
      "source": [
        "lenet5 = LeNet5()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMA4Lgl4Sv4k"
      },
      "source": [
        "lenet5.fit(X_train, y_train, optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYtGWthpSv4k"
      },
      "source": [
        "lenet5.train(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=64, epochs=20, callbacks=[ch, es, lr, mal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwZb85IoSv4k"
      },
      "source": [
        "lenet5.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kEr4yp6bnxi"
      },
      "source": [
        "##MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfpjTYD1bou_"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJLPX2i7SwK0"
      },
      "source": [
        "lenet5 = LeNet5()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JZKQtizSwK0"
      },
      "source": [
        "lenet5.fit(X_train, y_train, optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19zdW4HoSwK0"
      },
      "source": [
        "lenet5.train(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=64, epochs=20, callbacks=[ch, es, lr, mal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBJQY38iSwK0"
      },
      "source": [
        "lenet5.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npb5vwblbpTF"
      },
      "source": [
        "##FashionMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ep0owdabrDf"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFEFpflOSwb0"
      },
      "source": [
        "lenet5 = LeNet5()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h263QxtVSwb0"
      },
      "source": [
        "lenet5.fit(X_train, y_train, optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JZw3cUjSwb0"
      },
      "source": [
        "lenet5.train(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=64, epochs=20, callbacks=[ch, es, lr, mal])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1CD-Qd_Swb0"
      },
      "source": [
        "lenet5.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}